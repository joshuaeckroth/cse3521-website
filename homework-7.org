#+SETUPFILE: setup.org
#+TITLE: Homework 7

* Task 1 (20 pts)

Execute the k-means algorithm by hand on the following data:

| item # |   w |   x |   y |   z | true label |
|--------+-----+-----+-----+-----+------------|
|      1 | 1.0 | 1.0 | 0.0 | 1.0 | A          |
|      2 | 0.0 | 0.0 | 1.0 | 0.0 | B          |
|      3 | 2.0 | 2.0 | 0.0 | 2.0 | A          |
|      4 | 0.0 | 0.0 | 1.0 | 1.0 | B          |
|      5 | 2.0 | 2.0 | 0.0 | 2.0 | A          |
|      6 | 0.0 | 2.0 | 1.0 | 1.0 | B          |

Use $k=2$. Show the centroids as they change, and give the final
centroids. You must choose random (or not so random) starting centroid
values. Finally, give the confusion matrix.

* Task 2 (20 pts)

Run the k-means algorithm in Weka using this dataset: [[./iris.arff][iris.arff]] (iris
species clustering).

Choose $k=3$ and $k=4$. Give the confusion matrix for each value of
$k$. Also report the percent of correctly classified instances for
each class, for each $k$.

* Task 3 (20 pts)

Execute the k-nearest neighbor algorithm by hand on the clusters found
from task 1 (or make up random clusters by labeling the points from
task 1). Use $k = 2$. Classify the data point: $<1, 3, 0, 2>$.

* Task 4 (20 pts)

Run the k-nearest neighbor in Weka using this dataset: [[./letter.arff][letter.arff]]
(handwritten letter classification). Find a good value of $k$. Report
the accuracy and give the confusion matrix for the best accuracy.

* Task 5 (20 pts)

Explain the differences between k-means and k-nearest neighbor
algorithms. What does each accomplish, and when/why might you use
both?

* Extra credit (10 pts)

Play around with Weka; report which classifier algorithm performs best
(or nearly best) for classifying the [[./letter.arff][letter.arff]] data.


#+INCLUDE: footer.org
